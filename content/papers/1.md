---
title: "Estimating label quality and errors in semantic segmentation data via any model" 
date: 2023-07-11
url: /papers/1/
aliases: 
    - /papers/1.html
tags: ["data centric ","machine learning","computer vision","cleanlab"]
author: "Vedang Lad, Jonas Mueller"
description: "This paper proposes a novel method to find label errors in semantic segmentation datasets." 
summary: "The soft-minimum of the model-estimated likelihoods of each pixel's annotated class -- that is particularly effective to identify images that are mislabeled, across multiple types of annotation error" 
cover:
    image: "/papers/1.png"
    alt: "Error detection for semantic segmentation, see paper for details."
    relative: false
editPost:
    URL: "https://dmlr.ai/assets/accepted-papers/110/CameraReady/segment_errors_icml2023.pdf"
    Text: "ICML 2023"

---

---

##### Download

+ [Paper](/papers/1a.pdf)
+ [Code and data](https://github.com/cleanlab/cleanlab/tree/master/cleanlab/segmentation)
+ [Tutorial](https://docs.cleanlab.ai/stable/tutorials/segmentation.html)

---

##### Abstract

The labor-intensive annotation process of semantic segmentation datasets is often prone to errors, since humans struggle to label every pixel correctly. We study algorithms to automatically detect such annotation errors, in particular methods to score label quality, such that the images with the lowest scores are least likely to be correctly labeled. This helps prioritize what data to review in order to ensure a high-quality training/evaluation dataset, which is critical in sensitive applications such as medical imaging and autonomous vehicles. Widely applicable, our label quality scores rely on probabilistic predictions from a trained segmentation model -- any model architecture and training procedure can be utilized. Here we study 7 different label quality scoring methods used in conjunction with a DeepLabV3+ or a FPN segmentation model to detect annotation errors in a version of the SYNTHIA dataset. Precision-recall evaluations reveal a score -- the soft-minimum of the model-estimated likelihoods of each pixel's annotated class -- that is particularly effective to identify images that are mislabeled, across multiple types of annotation error.
