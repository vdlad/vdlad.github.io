---
title: "The Remarkable Robustness of LLMs: Stages of Inference?" 
date: 2024-06-27
url: /papers/3/
aliases: 
    - /papers/3.html
tags: ["large language models","robustness","AI safety","machine learning"]
author: "Vedang Lad, Wes Gurnee, Max Tegmark"
description: "We demonstrate and investigate the remarkable robustness of Large Language Models by deleting and swapping adjacent layers."
summary: "We find that deleting and swapping interventions retain 72-95% of the original model’s prediction accuracy without fine-tuning, and hypothesize the existence of four universal stages of inference across eight different models."
cover:
    image: "/papers/3.png"
    alt: "Stages of inference in large language models."
    relative: false
editPost:
    URL: "https://arxiv.org/pdf/2406.19384"
    Text: "Preprint"
---

---

##### Download
 
+ [Paper](/papers/3.pdf)
+ [Code and data](https://github.com/vdlad/Remarkable-Robustness-of-LLMs)


---

##### Abstract

We demonstrate and investigate the remarkable robustness of Large Language Models by deleting and swapping adjacent layers. We find that deleting and swapping interventions retain 72-95% of the original model’s prediction accuracy without fine-tuning, whereas models with more layers exhibit more robustness. Based on the results of the layer-wise intervention and further experiments, we hypothesize the existence of four universal stages of inference across eight different models: detokenization, feature engineering, prediction ensembling, and residual sharpening. The first stage integrates local information, lifting raw token representations into higher-level contextual representations. Next is the iterative refinement of task and entity-specific features. Then, the second half of the model begins with a phase transition, where hidden representations align more with the vocabulary space due to specialized model components. Finally, the last layer sharpens the following token distribution by eliminating obsolete features that add noise to the prediction.